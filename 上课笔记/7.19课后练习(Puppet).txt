7.19课后练习(Puppet)



$ cd ~
$ mkdir manifests
$ cd manifests

1、使用puppet apply创建一个nginx组
	$ vim nginx.pp
	group{'nginx':
	        name    => 'nginx',
	        ensure  => present,
	        system  => true,
	}

	$ puppet apply -d -v nginx.pp




2、创建redis用户和组
	$ vim redis.pp
	user{'redis':
	        name    => 'redis',
	        ensure  => present,
	        system  => true,
	        require => Group['redis'],
	}

	group{'redis':
	        name    => 'redis',
	        ensure  => present,
	        system  => true,
	}

	$ puppet apply -d -v --noop redis.pp
	$ puppet apply -d -v redis.pp



3、安装一个redis程序包，使用本地安装包
	$ wget ftp://172.16.0.1/pub/Sources/7.x86_64/redis/redis-3.2.3-1.el7.x86_64.rpm
	或者
	$ wget http://dl.fedoraproject.org/pub/epel/7/x86_64/r/redis-3.2.3-1.el7.x86_64.rpm

	$ vim package.pp
	package{'redis':
	        ensure  => installed,
	        source  => '/root/manifests/redis-3.2.3-1.el7.x86_64.rpm',
	        provider        => yum,
	}



4、启动redis服务
	$ vim service.pp
	service{'redis':
		ensure	=> running,
		enable	=> true,
	}


5、安装一个nginx，并启动服务
	$ vim nginx.pp
	package{'nginx':
        ensure  => installed,
	}

	service{'nginx':
	        ensure  => running,
	        enable  => true,
	        require => Package['nginx'],
	}



6、修改nginx的配置文件为我们自定义的
	$ vim file.pp
	file{'nginx':
	        ensure  =>      file,
	        path    =>      '/etc/nginx/nginx.conf',
	        source  =>      '/root/manifests/nginx.conf',
	        owner   =>      'nginx',
	        group   =>      'root',
	        mode    =>      0644,
	}



7、配置文件修改后，通知给service：
	$ vim service2.pp
	package{'nginx':
	        ensure  => installed,
	}

	file{'nginx':
	        path    => '/etc/nginx/nginx.conf',
	        source  => '/root/manifests/nginx.conf',
	        ensure  => file,
	        require => Package['nginx'],
	}

	service{'nginx':
	        ensure  => running,
	        enable  => true,
	        require => Package['nginx'],
	        subscribe       => File['nginx'],
	}

	$ vim nginx.conf 
	server {
        listen       8080 default_server;
        listen       [::]:80 default_server;
        server_name  _;
        root         /usr/share/nginx/html;

        # Load configuration files for the default server block.
        include /etc/nginx/default.d/*.conf;

        location / {
                proxy_pass      http://172.16.1.70:80;
        }

        location ~* \.(jpg|jpeg|png|gif) {
                proxy_pass      http://172.16.1.30:80;
        }
    }

    $ puppet apply -d -v --noop service2.pp
    $ puppet apply -d -v service2.pp

    $ ss -tnl






8、配置链式依赖

	-> ：表示此资源必须要在下一个资源之前执行
	~> ：表示此资源如果变化了，则通知下一个资源，进行fresh刷写操作

	$ vim service2.pp
	package{'nginx':
	        ensure  => installed,
	} ->	#表示package资源要先于file资源执行


	file{'nginx':
	        path    => '/etc/nginx/nginx.conf',
	        source  => '/root/manifests/nginx.conf',
	        ensure  => file,
	} ~>	# 表示file资源如果变化，则通知service资源进行刷写fresh操作

	service{'nginx':
	        ensure  => running,
	        enable  => true,
	}


	或者使用此配置，功能相同

	package{'nginx':
        ensure  => installed,
	}

	file{'nginx':
	        path    => '/etc/nginx/nginx.conf',
	        source  => '/root/manifests/nginx.conf',
	        ensure  => file,
	}

	service{'nginx':
	        ensure  => running,
	        enable  => true,
	}

	Package['nginx'] -> File['nginx'] ~> Service['nginx']


	$ puppet apply -d -v --noop service2.pp
	$ puppet apply -d -v service2.pp





9、配置目录进行复制
	$ vim dir.pp
	file{'/tmp/pam.d':
			# 指明为目录
	        ensure  => directory,
	        source  => '/etc/pam.d',
	        # 递归复制
	        recurse => true,
	}

	$ puppet apply -d -v --noop dir.pp
	$ puppet apply -d -v dir.pp




10、创建目录
	$ vim exec1.pp
	exec{'/usr/bin/mkdir':
	        command => 'mkdir /tmp/testdir',
	        path    => '/usr/bin',
	        # 如果目录存在，则不执行创建操作
	        creates => '/tmp/testdir',
	}




11、创建用户，只有当程序包安装了，才会创建
	$ vim exec2.pp
	package{'mogilefs':
	        ensure  => latest,
	        provider        => yum,
	}

	exec{'adduser':
	        command => 'useradd -r mogilefs',
	        path    => '/usr/sbin/:/usr/bin/:/bin:/sbin',
	        unless  => 'id mogilefs',
	        refreshonly     => true,
	        subscribe       => Package['mogilefs'],
	}




12、创建定时任务
	
	$ vim cron.pp
	cron{'timesync':
	        command => '/usr/bin/ntpdate 172.16.0.1 &> /dev/null',
	        ensure  => present,
	        minute  => '*/3',
	        user    => 'root',
	}

	$ puppet apply -d -v cron.pp
	$ crontab -l
	# HEADER: This file was autogenerated at 2017-07-19 21:37:24 +0800 by puppet.
	# HEADER: While it can still be managed manually, it is definitely not recommended.
	# HEADER: Note particularly that the comments starting with 'Puppet Name' should
	# HEADER: not be deleted, as doing so could cause duplicate cron jobs.
	# Puppet Name: timesync
	*/3 * * * * /usr/bin/ntpdate 172.16.0.1 &> /dev/null


	# 删除定时任务
	$ vim cron.pp
	cron{'timesync':
	        command => '/usr/bin/ntpdate 172.16.0.1 &> /dev/null',
	        # 删除
	        ensure  => absent,
	        minute  => '*/3',
	        user    => 'root',
	}

	$ puppet apply -d -v cron.pp





13、定义通知脚本
	$ vim notify.pp
	notify{'sayhi':
        message => 'how old r u ?',
        name    => 'hi',
	}

	$ puppet apply notify.pp






14、使用变量创建一个用户和组
	$ vim var.pp
	$username = 'maxie'

	group{"$username":
	        ensure  => present,
	        system  => true,
	} ->

	user{"$username":
	        ensure  => present,
	        gid     => "$username",
	}

	$ puppet apply -d -v var.pp


	# 删除用户和组
	$username = 'maxie'

	group{"$username":
	        ensure  => absent,
	        system  => true,
	        require => User[$username],
	}

	user{"$username":
	        ensure  => absent,
	        gid     => "$username",
	}

	$ puppet apply -d -v var.pp







15、使用case定义一个变量，并根据某个系统变量的值，来进行赋值
	$ vim case.pp
	case $operatingsystem {
	        RedHat, CentOS, Fedora: { $webserver = 'httpd' }
	        /(?i-mx:debian|ubuntu)/: { $webserver = 'apache2' }
	        default: { $webserver = 'httpd' }
	}

	package{"$webserver":
	        ensure  => installed,
	}

	$ puppet apply -d -v --noop case.pp
	$ puppet apply -d -v case.pp

	$ rpm -q httpd
	httpd-2.4.6-40.el7.centos.x86_64






16、使用selector完成任务15
	$ vim select.pp
	$webserver = $opeartingsystem ? {
	        /(?i-mx:ubuntu|debian)/ => 'apache2',
	        /(?i-mx:redhat|centos|fedora)/ => 'httpd',
	        default => 'httpd',
	}

	package{"$webserver":
	        ensure  => present,
	}

	$ puppet apply -v -d --noop select.pp
	$ puppet apply -v -d select.pp



17、定义一个类，并引用：
	$ vim class1.pp
	class nginx {
	        package{'nginx':
	                ensure  =>      installed,
	        } ->

	        file{'nginx':
	                ensure  =>      file,
	                path    =>      '/etc/nginx/nginx.conf',
	                source  =>      '/root/manifests/nginx.conf',
	                owner   =>      'root',
	                group   =>      'root',
	                mode    =>      0644,
	        } ~>

	        service{'nginx':
	                ensure  =>      running,
	                enable  =>      true,
	        }
	}

	# transfer class
	include nginx

	$ puppet apply -d -v --noop class1.pp
	$ puppet apply -d -v class1.pp








18、定义一个类，引用多个变量，判断系统的类别是centos7、还是6。对MySQL进行安装

	$ vim mysql-install.pp
	class dbserver($version,$server) {
		package{"$version":
			ensure	=> latest,
		} ->

		service{"$server":
			ensure	=> running,
			enable	=> true,
		}

	}

	if $operatingsystem == "CentOS" {
		$dbpkg = $operatingsystemmajrelease ? {
			7 => 'mariadb-server',
			default => 'mysqld-server',
		}

		$service = $operatingsystemmajrelease ? {
			7 => 'mariadb.service',
			default => 'mysqld',
		}
	}

	class{'dbserver':
		version => "$dbpkg",
		server	=> "$service",
	}



19、创建多个子类，继承父类
	$ vim nginx-install.pp
	class nginx {
		package{'nginx':
			ensure	=>	installed,
		} ->

		service{'nginx':
			ensure	=>	running,
			enable	=>	true,
		}
	}

	class nginx::web inherits nginx{
		file{'nginx':
			ensure	=>	file,
			path	=>	'/etc/nginx/nginx.conf',
			source	=>	'/root/manifests/nginx-web.conf',
		}

		Package['nginx'] -> File['nginx'] ~> Service['nginx']
	}

	class nginx::webproxy inherits nginx{

	}

	class nginx::mysqlproxy inherits nginx{

	}

	include nginx::web










20、在子类中覆盖父类的值，或者在子类中增加父类某个属性的值

	# 覆盖
	$ vim nginx-install.pp
	class nginx::webproxy inherits nginx{
	        file{'nginx':
	                ensure  =>      file,
	                path    =>      '/etc/nginx/nginx.conf',
	                source  =>      '/root/manifests/nginx-webproxy.conf',
	        }

	        # 覆盖父类中的Service资源的enable的值为false
	        Service['nginx']{
	                enable  =>      false,
	        }

	        Package['nginx'] -> File['nginx'] ~> Service['nginx']

	}


	# 新增

	class nginx::webproxy inherits nginx{
	        file{'nginx':
	                ensure  =>      file,
	                path    =>      '/etc/nginx/nginx.conf',
	                source  =>      '/root/manifests/nginx-webproxy.conf',
	        }

	        Service['nginx']{
	                enable  =>      false,
	                # 新增依赖关系
	                require +>      File['nginx'],
	        }


	}













21、'puppet模板简单练习'
	(1) 实现nginx配置文件中work_process的数量为 CPU核心数
		$ vim template.pp 
		package{'nginx':
		        ensure  =>      installed,
		}

		file{'nginx.conf':
		        ensure  =>      file,
		        path    =>      '/etc/nginx/nginx.conf',
		        content =>      template('/root/manifests/nginx.conf.erb'),
		}

		$ vim nginx.conf.erb
		worker_processes <%= @processorcount %>;

		$ puppet apply -d -v template.pp


	(2) 使用模块自带函数，使用facter获取的变量，对模板文件进行设置，并使得获取的变量进行乘法运算
		$ vim template.pp 
		package{'nginx':
		        ensure  =>      installed,
		}

		file{'nginx.conf':
		        ensure  =>      file,
		        path    =>      '/etc/nginx/nginx.conf',
		        content =>      template('/root/manifests/nginx.conf.erb'),
		}

		$ vim nginx.conf.erb
		# 注意这里是字符串相乘，也就是字符串相加，最后得出的数应为@processorcount@processorcount，拼接而成，如果@processorcount为1，则最后的数为11
		worker_processes <%= @processorcount * 2 %>;

		$ puppet apply -d -v template.pp

		$ vim /etc/nginx/nginx.conf
		worker_processes 11;


	(3) 使用模板语言中对变量运算的方法，对worker进程进行加减

		$ vim nginx.conf.erb
		worker_processes <%= Integer(@processorcount) + 1 %>;

		$ puppet apply -d -v template.pp

		$ vim /etc/nginx/nginx.conf 
		worker_processes 2;
















22、定义chrony资源清单'模块'
	$ mkdir /root/modules
	$ cd modules/
	$ mkdir -pv  chrony/{manifests,files,templates,lib,spec,tests}
	$ cd chrony/manifests/
	$ vim init.pp
	# Class: chrony
	#
	# This module manages CHRONY
	#
	#

	class chrony {
	        package{'chrony':
	                ensure  => latest,
	        } ->

	        file{'chrony.conf':
	                ensure  => file,
	                path    => '/etc/chrony.conf',
	                source  => 'puppet:///modules/chrony/chrony.conf',
	        } ~>

	        service{'chronyd':
	                ensure  => running,
	                enable  => true,
	        }
	}


	$ cp /etc/chrony.conf ../files/
	$ cd /root/modules
	$ cp -a chrony/ /etc/puppet/modules/

	$ puppet apply -d -v --noop -e 'include chrony'
	$ puppet apply -d -v  -e 'include chrony'






23、定义nginx模块：
	$ cp /root/manifests/nginx-webproxy.conf /root/modules/nginx/files/
	$ mkdir -pv  /root/modules/nginx/{manifests,files,templates,lib,spec,tests}
	
	$ vim /root/modules/nginx/manifests/init.pp
	# Class: nginx
	#
	# This module manages NGINX
	#
	#
	class nginx {
	        package{'nginx':
	                ensure  =>      latest,
	        } ->

	        service{'nginx':
	                ensure  =>      running,
	                enable  =>      true,
	        }
	}

	$ vim /root/modules/nginx/manifests/nginx-webproxy.pp
	class nginx::webproxy inherits nginx {
	        file{'nginx.conf':
	                path    =>      '/etc/nginx/nginx.conf',
	                source  =>      'puppet:///modules/nginx/nginx-webproxy.conf',
	        }

	        Package['nginx'] -> File['nginx.conf'] ~> Service['nginx']
	}


	$ cp -a /root/modules/nginx/ /etc/puppet/modules/
	$ puppet module list
	/etc/puppet/modules
	├── chrony (???)
	└── nginx (???)
	/usr/share/puppet/modules (no modules installed)

	# 执行模块
	$ puppet apply -d -v  -e 'include nginx::webproxy'



	'新增一个子类：'(使用模板)
		$ vim nginx/manifests/web.pp
		class nginx::web inherits nginx{
		    file{'nginx.conf':
		        path     => '/etc/nginx/nginx.conf',
		        content => template('nginx/nginx.conf.erb'),
		    }

		    Package['nginx'] -> File['nginx.conf'] ~> Service['nginx']
		}

		$ cp /root/manifests/nginx.conf.erb /etc/puppet/modules/nginx/templates/
		$ vim /etc/puppet/modules/nginx/templates/nginx.conf.erb
		worker_processes <%= Integer(@processorcount) + 1 %>;

		$ puppet apply -d -v  -e 'include nginx::web'


















24、创建一个nginx模块，能够实现：
	(1) 反代http请求
	(2) 对动态请求发送到httpd+tomcat的虚拟主机上，能够负载均衡
	
	1、安装nginx，并修改配置文件，准备最好为我们模板
		$ yum install nginx 
		$ vim /etc/nginx/nginx.conf
		server {
		        listen 80;
		        server_name     maxie.io;
		        index   index.html;

		#        location / {
		#        proxy_pass    http://172.16.1.70:80;
		#        }


		        location / {
		        proxy_set_header    X-Forwarded-For $remote_addr;
		        proxy_buffering        off;
		        proxy_pass        http://172.16.1.70:80;
		        }

		}

	2、配置模块：
		$ mkdi /etc/puppet/modules/nginx/{manifests,files,templates,lib,spec,tests}
		$ cd /etc/puppet/modules/nginx/
		$ vim manifests/init.pp
		class nginx {
	        package{'nginx':
	                ensure  => latest,
	        } ->

	        service{'nginx':
	                ensure  => running,
	                enable  => true,
            }
        }


        $ vim manifests/webproxy.pp
        class nginx::webproxy inherits nginx {
			file{'nginx.conf':
				ensure	=> file,
				path	=> '/etc/nginx/nginx.conf',
				content	=> template('nginx/nginx-webproxy.conf.erb'),
			}
			
			Package['nginx'] -> File['nginx.conf']  ~> Service['nginx']
		}

		
		$ vim manifests/tomcatsrvs.pp
		class nginx::tomcatsrvs inherits nginx {
			file{'nginx-tomcat.conf':
				ensure	=> file,
				path	=> '/etc/nginx/nginx.conf',
				content	=> template('nginx/nginx-tomcat.conf.erb'),
			}
			
			Package['nginx'] -> File['nginx-tomcat.conf']  ~> Service['nginx']
		}




		'定义配置文件模板'
			$ vim templates/nginx-webproxy.conf.erb
			# For more information on configuration, see:
			#   * Official English Documentation: http://nginx.org/en/docs/
			#   * Official Russian Documentation: http://nginx.org/ru/docs/

			user nginx;
			worker_processes <%= @processorcount %>;
			error_log /var/log/nginx/error.log;
			pid /run/nginx.pid;

			# Load dynamic modules. See /usr/share/nginx/README.dynamic.
			include /usr/share/nginx/modules/*.conf;

			events {
			    worker_connections 1024;
			}

			http {
			    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
			                      '$status $body_bytes_sent "$http_referer" '
			                      '"$http_user_agent" "$http_x_forwarded_for"';

			    access_log  /var/log/nginx/access.log  main;

			    sendfile            on;
			    tcp_nopush          on;
			    tcp_nodelay         on;
			    keepalive_timeout   65;
			    types_hash_max_size 2048;

			    include             /etc/nginx/mime.types;
			    default_type        application/octet-stream;

			    # Load modular configuration files from the /etc/nginx/conf.d directory.
			    # See http://nginx.org/en/docs/ngx_core_module.html#include
			    # for more information.
			    include /etc/nginx/conf.d/*.conf;

			    server {
			        listen       80 default_server;
			        listen       [::]:80 default_server;
			        root         /usr/share/nginx/html;

			        include /etc/nginx/default.d/*.conf;

				server_name	<%= @domain %>;
				index 	index.html;

			        location / {
			       		proxy_set_header    X-Forwarded-For $remote_addr;
			        	proxy_buffering        off;
			        	proxy_pass        http://node2:808;
			        }
				

			        error_page 404 /404.html;
			            location = /40x.html {
			        }

			        error_page 500 502 503 504 /50x.html;
			            location = /50x.html {
			        }
			    }
			}


			$ vim templates/nginx-tomcat.conf.erb
			# For more information on configuration, see:
			#   * Official English Documentation: http://nginx.org/en/docs/
			#   * Official Russian Documentation: http://nginx.org/ru/docs/

			user nginx;
			worker_processes <%= @processorcount %>;
			error_log /var/log/nginx/error.log;
			pid /run/nginx.pid;

			# Load dynamic modules. See /usr/share/nginx/README.dynamic.
			include /usr/share/nginx/modules/*.conf;

			events {
			    worker_connections 1024;
			}

			http {
			    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
			                      '$status $body_bytes_sent "$http_referer" '
			                      '"$http_user_agent" "$http_x_forwarded_for"';

			    access_log  /var/log/nginx/access.log  main;

			    sendfile            on;
			    tcp_nopush          on;
			    tcp_nodelay         on;
			    keepalive_timeout   65;
			    types_hash_max_size 2048;

			    include             /etc/nginx/mime.types;
			    default_type        application/octet-stream;

			    # Load modular configuration files from the /etc/nginx/conf.d directory.
			    # See http://nginx.org/en/docs/ngx_core_module.html#include
			    # for more information.
			    include /etc/nginx/conf.d/*.conf;

			    upstream tomcatsrvs {
				server node2.maxie.io:808;
			        server node3.maxie.io:808;
			    }

			    server {
			        listen       80 default_server;
			        listen       [::]:80 default_server;
			        root         /usr/share/nginx/html;

			        include /etc/nginx/default.d/*.conf;

				server_name	<%= @domain %>;
				index 	index.html;

			        location / {
			       		proxy_set_header    X-Forwarded-For $remote_addr;
			        	proxy_buffering        off;
			        	proxy_pass        http://tomcatsrvs;
			        }
				

			        error_page 404 /404.html;
			            location = /40x.html {
			        }

			        error_page 500 502 503 504 /50x.html;
			            location = /50x.html {
			        }
			    }

			}









24、创建一个mariadb的模块：
	(1) 初始化环境 
		$ mkdir -pv /etc/puppet/modules/mariadb/{manifests,templates,files,lib,tests}

		$ cp /etc/my.cnf.d/server.cnf /etc/puppet/modules/mariadb/templates/server.cnf.erb

	(2) 制作模板文件
		$ cd /etc/puppet/modules/mariadb/
		$ vim templates/server.conf.erb
		#
		# These groups are read by MariaDB server.
		# Use it for options that only the server (but not clients) should see
		#
		# See the examples of server my.cnf files in /usr/share/mysql/
		#

		# this is read by the standalone daemon and embedded servers
		[server]
		skip_name_resolve=ON
		innodb_file_per_table=ON
		log-bin=mysql_bin

		# this is only for the mysqld standalone daemon
		[mysqld]

		# this is only for embedded server
		[embedded]

		# This group is only read by MariaDB-5.5 servers.
		# If you use the same .cnf file for MariaDB of different versions,
		# use this group for options that older servers don't understand
		[mysqld-5.5]

		# These two groups are only read by MariaDB servers, not by MySQL.
		# If you use the same .cnf file for MySQL and MariaDB,
		# you can put MariaDB-only options here
		[mariadb]

		[mariadb-5.5]



		'制作sql脚本'

		$ vim files/solodb.sql
		create database solo;

		grant all on solo.* to 'solo'@'172.16.%.%' identified by 'root@123';

		flush privileges;



	(3) 制作模块
		$ vim manifests/init.pp
		class mariadb($datadir='/var/lib/mysql') {
			package{'mariadb-server':
				ensure	=> installed,
			}

			file{"$datadir":
				ensure	=> directory,
				owner	=> mysql,
				group	=> mysql,
				require	=> [ Package['mariadb-server'], Exec['createdir'], ],	
			}
			
			exec{'createdir':
				command	=> "mkdir -pv $datadir",
				require	=> Package['mariadb-server'],
				path	=> '/bin:/sbin:/usr/bin:/usr/sbin',
				creates	=> "$datadir",
			}

			file{'server.cnf':
				ensure	=> file,
				path	=> '/etc/my.cnf.d/server.cnf',
				content	=> template('mariadb/server.cnf.erb'),
				require	=> Package['mariadb-server'],
				notify	=> Service['mariadb'],
			}

			service{'mariadb':
				ensure	=> running,
				enable	=> true,
				require	=> [ Exec['createdir'], File["$datadir"], ],
			}
		}

		$ vim manifests/database.pp
		class mariadb::database inherits mariadb {
			file{'solodb.sql':
				ensure	=> file,
				path	=> '/var/lib/mysql/solodb.sql',
				source	=> 'puppet:///modules/mariadb/solodb.sql'
			}	

			# only run once
			exec{'createdb':
				command	=> 'mysql < /var/lib/mysql/solodb.sql',
				path    => '/bin:/sbin:/usr/bin:/usr/sbin',
				require	=> Package['mariadb-server'],
				unless  => "mysql -usolo -proot@123 -h$ipaddress",
			}

			Service['mariadb'] -> File['solodb.sql'] -> Exec['createdb']
		}



















24、创建一个httpd反代tomcat的模块：
	(1) 先要安装httpd，测试好之后，将配置文件做成模板
		$ yum install -y httpd 
		$ vim /etc/httpd/conf/httpd.conf 
		# 将默认监听80端口改为808
		Listen 808

		# 编辑虚拟主机配置文件
		$ vim /etc/httpd/conf.d/maxie.conf 

		<VirtualHost 172.16.1.70:808>
		        ServerName maxie.io:808
		        ProxyRequests Off
		        ProxyVia On
		        ProxyPreserveHost On
		        <Proxy *>
		                Require all granted
		        </Proxy>
		        ProxyPass       /       http://172.16.1.70:80/

		        <Location />
		                Require all granted
		        </Location>
		       CustomLog "/web/blog/logs/maxie_access.log" combined
		</VirtualHost>



	(2) 此配置文件经过检验，可以反代tomcat请求，所以我们将其制作成模板文件。
		并制作httpd的模块

		$ cd /etc/puppet/modules
		$ mkdir -pv httpd/{manifests,templates,files,lib,tests}
		$ cd httpd

		'模板配置文件：'
			$ vim templates/httpd.conf.erb
			# 只需将默认的httpd.conf中的listen修改为808即可
			Listen 808

		'# 虚拟主机配置文件'
			$ vim templates/vhost.conf.erb
			<VirtualHost <%= @ipaddress %>:808>
			        ServerName maxie.io:808
			        ProxyRequests Off
			        ProxyVia On
			        ProxyPreserveHost On
			        <Proxy *>
			                Require all granted
			        </Proxy>
			        ProxyPass       /       http://<%= @ipaddress %>:80/

			        <Location />
			                Require all granted
			        </Location>
			#       DocumentRoot "/web/blog/"
			#       <Directory "/web/blog/">
			#               Options FollowSymLinks
			#               AllowOverride None
			#               Require all granted
			#               DirectoryIndex index.html
			#       </Directory>
			        CustomLog "/web/blog/logs/maxie_access.log" combined
			</VirtualHost>

		'puppet文件配置'
			# init.pp
			$ vim manifests/init.pp
			class httpd{
			        package{'httpd':
			                ensure  => latest,
			        }

			        service{'httpd':
			                ensure  => running,
			                enable  => true,
			        }
			}

			# httpdconf.pp
			class httpd::httpdconf inherits httpd {
			        file{'httpd.conf':
			                ensure  => file,
			                path    => '/etc/httpd/conf/httpd.conf',
			                content => template('httpd/httpd.conf.erb'),
			        }

			        Package['httpd'] -> File['httpd.conf'] ~> Service['httpd']
			}


			# vhost.pp
			class httpd::vhost inherits httpd {
			        exec{'mkdir':
			                command => 'mkdir -p /web/blog/logs/',
			                path    => '/usr/bin:/usr/sbin/:/bin:/sbin',
			                creates => '/web/blog/logs',
			                before  => [ File['vhost.conf'], Service['httpd'] ],
			        }

			        file{'vhost.conf':
			                ensure  => file,
			                path    => '/etc/httpd/conf.d/vhost.conf',
			                content => template('httpd/vhost.conf.erb'),
			        }


			        Package['httpd'] -> File['vhost.conf'] ~> Service['httpd']
			}



	(3) 运行
		$ puppet apply -d -v --noop -e 'include httpd'
		$ puppet apply -d -v --noop -e 'include httpd::httpdconf'
		$ puppet apply -d -v --noop -e 'include httpd::vhost'

		$ puppet apply -d -v  -e 'include httpd'
		$ puppet apply -d -v  -e 'include httpd::httpdconf'
		$ puppet apply -d -v  -e 'include httpd::vhost'




















24、创建一个Tomcat模块：
	(1) tomcat模板配置文件：
		绑定80端口的软件：https://s3.amazonaws.com/aaronsilber/public/authbind-2.1.1-0.1.x86_64.rpm

		1)'安装'
		$ yum install -y java-1.8.0-openjdk-devel tomcat tomcat-lib tomcat-admin-webapps tomcat-webapps tomcat-docs-webapp
		
		2)'# 设置管理员账号和密码'
			$ vim /etc/tomcat/tomcat-user.xml
			<role rolename="admin-gui"/>
			<role rolename="manager-gui"/>
			<user username="root" password="root@123" roles="manager-gui"/>
			<user username="tomcat" password="root@123" roles="admin-gui"/>



		3)'# 设定tomcat监听80端口'
		$ vim /etc/tomcat/server.xml 
		Connector port="80" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" />


        4)'下载authbind绑定80端口的软件'
	       	$ wget https://s3.amazonaws.com/aaronsilber/public/authbind-2.1.1-0.1.x86_64.rpm
	       	$ yum install -y authbind-2.1.1-0.1.x86_64.rpm
	       	$ touch /etc/authbind/byport/80
	       	$ chown tomcat.tomcat  /etc/authbind/byport/80
	       	$ chmod 755 /etc/authbind/byport/80

	      
	    5)'拷贝solo博客程序'
	       	$ scp maxie@172.16.1.11:/Users/machiyuan/Downloads/LinuxPackages/solo-2.1.0.war /root
	       	$ mv solo-2.1.0.war solo.war
	       	$ mv solo.war /usr/share/tomcat/webapps

	    6)'启动tomcat服务'
	       	# 运行为80端口
	       	$ authbind --deep /usr/libexec/tomcat/server start &
	       	# 如果想用后台运行使用
	       	$ nohup authbind --deep /usr/libexec/tomcat/server start & 

	    7)'当服务启动后，自动解压solo.war，之后停止tomcat服务，开始配置solo博客'
			$ cd /usr/share/tomcat/webapps
			# 将默认程序移到家目录下
			$ mv ROOT /root/
			# 将solo博客设为默认程序
			$ mv solo ROOT
			$ cd ROOT 
			

			$ vim /usr/share/tomcat/webapps/ROOT/WEB-INF/classes/local.properties
			# 只需开启以下的信息，其他全部注释掉即可 也就是H2数据库，solo自带的数据库
			runtimeDatabase=MYSQL
			# solo数据库授权连接的用户
			jdbc.username=solo
			# solo用户的密码
			jdbc.password=root@123
			jdbc.driver=com.mysql.jdbc.Driver
			# 数据库IP地址
			jdbc.URL=jdbc:mysql://172.16.1.70:3306/solo?useUnicode=yes&characterEncoding=utf8
			jdbc.pool=druid

			# The minConnCnt MUST larger or equal to 3
			jdbc.minConnCnt=5
			jdbc.maxConnCnt=10

			# Be care to change the transaction isolation
			jdbc.transactionIsolation=REPEATABLE_READ

			# The specific table name prefix
			jdbc.tablePrefix=b3_solo




			'修改第二个配置文件'
			$ vim ROOT/WEB-INF/classes/latke.properties
			#### Server ####
			# Browser visit protocol
			serverScheme=http
			# Browser visit domain name
			serverHost=maxie.io
			# Browser visit port, 80 as usual, THIS IS NOT SERVER LISTEN PORT!
			serverPort=80

			#### Runtime Mode ####
			#runtimeMode=DEVELOPMENT
			runtimeMode=PRODUCTION
		

		8) 配置完文件之后，需要确定数据库启动,'再次启动tomcat'
			$ nohub authbind --deep /usr/libexec/tomcat/server start & 

		9) 打开网页测试即可
			





	(2) 编写tomcat模块：
		$ mkdir -pv /etc/puppet/modules/tomcat/{manifests,templates,files,lib,tests,spec}
		$ cd tomcat/manifests/
		

		# 初始化pp文件
		$ vim init.pp
		class tomcat {
				# 安装多个包时，可以使用name => 'java-1.8.0-openjdk-devel tomcat tomcat-lib'  --> 这样安装可以实现安装  ？？？也可能无法实现，不过需要测试才知道
				# 不过这里可能出现测试没有问题，安装会出问题
				# 只能是在titile中定义
		        package{['java-1.8.0-openjdk-devel','tomcat','tomcat-lib','tomcat-admin-webapps','tomcat-webapps']:
		                ensure  => latest,
		        }
		}

		$ vim conf.pp
		class tomcat::conf inherits tomcat{
		        file{'tomcat-user.xml':
		                ensure  => file,
		                path    => '/etc/tomcat/tomcat-users.xml',
		                content => template('tomcat/tomcat-users.xml.erb'),
		        }

		        file{'server.xml':
		                ensure  => file,
		                path    => '/etc/tomcat/server.xml',
		                content => template('tomcat/server.xml.erb')
		                require => File['tomcat-user.xml'],
		        }

		        Package['java-1.8.0-openjdk-devel','tomcat','tomcat-lib','tomcat-admin-webapps','tomcat-webapps','authbind'] -> File['tomcat-user.xml'] 
		}

		
		$ vim blog.pp
		class tomcat::blog inherits tomcat {

			file{'ROOT':
		                ensure  => directory,
		                path    => '/usr/share/tomcat/webapps/ROOT/',
		                source  => 'puppet:///modules/tomcat/ROOT/',
		                replace => true,
		                recurse => true,
		                owner   => 'tomcat',
		                group   => 'tomcat',
		        }
		    # solo 博客数据库配置文件
			file{'local.properties':
				ensure	=> file,
				path	=> '/usr/share/tomcat/webapps/ROOT/WEB-INF/classes/local.properties',
				replace	=> true,
				owner	=> 'tomcat',
				group	=> 'tomcat',
				content	=> template('tomcat/local.properties.erb'),
				require	=> File['ROOT'],
			}

			Package['tomcat'] -> File['ROOT']

		}


		$ vim authbind.pp
		# 配置authbind软件，使tomcat运行在80端口
		class tomcat::authbind inherits tomcat {
		        package{'authbind':
		                ensure  => installed,
		                source  => 'puppet:///modules/tomcat/authbind-2.1.1-0.1.x86_64.rpm',
		                provider => rpm,
		        }

		        exec{'authbind':
		                command => 'setsid authbind --deep /usr/libexec/tomcat/server start',
		                path    => '/bin:/sbin:/usr/bin:/usr/sbin',
		                require => Package['authbind']
		        }

		        Package['tomcat'] -> Package['authbind']
		}



	(3) 拷贝所需的模板文件以及配置文件
		$ tomcat/templates/server.xml.erb
		# 只需将端口改为80即可，其他无需设置
		<?xml version='1.0' encoding='utf-8'?>
		<!--
		  Licensed to the Apache Software Foundation (ASF) under one or more
		  contributor license agreements.  See the NOTICE file distributed with
		  this work for additional information regarding copyright ownership.
		  The ASF licenses this file to You under the Apache License, Version 2.0
		  (the "License"); you may not use this file except in compliance with
		  the License.  You may obtain a copy of the License at

		      http://www.apache.org/licenses/LICENSE-2.0

		  Unless required by applicable law or agreed to in writing, software
		  distributed under the License is distributed on an "AS IS" BASIS,
		  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
		  See the License for the specific language governing permissions and
		  limitations under the License.
		-->
		<!-- Note:  A "Server" is not itself a "Container", so you may not
		     define subcomponents such as "Valves" at this level.
		     Documentation at /docs/config/server.html
		 -->
		<Server port="8005" shutdown="SHUTDOWN">
		  <!-- Security listener. Documentation at /docs/config/listeners.html
		  <Listener className="org.apache.catalina.security.SecurityListener" />
		  -->
		  <!--APR library loader. Documentation at /docs/apr.html -->
		  <Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" />
		  <!--Initialize Jasper prior to webapps are loaded. Documentation at /docs/jasper-howto.html -->
		  <Listener className="org.apache.catalina.core.JasperListener" />
		  <!-- Prevent memory leaks due to use of particular java/javax APIs-->
		  <Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" />
		  <Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" />
		  <Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" />

		  <!-- Global JNDI resources
		       Documentation at /docs/jndi-resources-howto.html
		  -->
		  <GlobalNamingResources>
		    <!-- Editable user database that can also be used by
		         UserDatabaseRealm to authenticate users
		    -->
		    <Resource name="UserDatabase" auth="Container"
		              type="org.apache.catalina.UserDatabase"
		              description="User database that can be updated and saved"
		              factory="org.apache.catalina.users.MemoryUserDatabaseFactory"
		              pathname="conf/tomcat-users.xml" />
		  </GlobalNamingResources>

		  <!-- A "Service" is a collection of one or more "Connectors" that share
		       a single "Container" Note:  A "Service" is not itself a "Container",
		       so you may not define subcomponents such as "Valves" at this level.
		       Documentation at /docs/config/service.html
		   -->
		  <Service name="Catalina">

		    <!--The connectors can use a shared executor, you can define one or more named thread pools-->
		    <!--
		    <Executor name="tomcatThreadPool" namePrefix="catalina-exec-"
		        maxThreads="150" minSpareThreads="4"/>
		    -->


		    <!-- A "Connector" represents an endpoint by which requests are received
		         and responses are returned. Documentation at :
		         Java HTTP Connector: /docs/config/http.html (blocking & non-blocking)
		         Java AJP  Connector: /docs/config/ajp.html
		         APR (HTTP/AJP) Connector: /docs/apr.html
		         Define a non-SSL HTTP/1.1 Connector on port 8080
		    -->
		    <Connector port="80" protocol="HTTP/1.1"
		               connectionTimeout="20000"
		               redirectPort="8443" />
		    <!-- A "Connector" using the shared thread pool-->
		    <!--
		    <Connector executor="tomcatThreadPool"
		               port="8080" protocol="HTTP/1.1"
		               connectionTimeout="20000"
		               redirectPort="8443" />
		    -->
		    <!-- Define a SSL HTTP/1.1 Connector on port 8443
		         This connector uses the BIO implementation that requires the JSSE
		         style configuration. When using the APR/native implementation, the
		         OpenSSL style configuration is required as described in the APR/native
		         documentation -->
		    <!--
		    <Connector port="8443" protocol="org.apache.coyote.http11.Http11Protocol"
		               maxThreads="150" SSLEnabled="true" scheme="https" secure="true"
		               clientAuth="false" sslProtocol="TLS" />
		    -->

		    <!-- Define an AJP 1.3 Connector on port 8009 -->
		    <Connector port="8009" protocol="AJP/1.3" redirectPort="8443" />


		    <!-- An Engine represents the entry point (within Catalina) that processes
		         every request.  The Engine implementation for Tomcat stand alone
		         analyzes the HTTP headers included with the request, and passes them
		         on to the appropriate Host (virtual host).
		         Documentation at /docs/config/engine.html -->

		    <!-- You should set jvmRoute to support load-balancing via AJP ie :
		    <Engine name="Catalina" defaultHost="localhost" jvmRoute="jvm1">
		    -->
		    <Engine name="Catalina" defaultHost="localhost">

		      <!--For clustering, please take a look at documentation at:
		          /docs/cluster-howto.html  (simple how to)
		          /docs/config/cluster.html (reference documentation) -->
		      <!--
		      <Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"/>
		      -->

		      <!-- Use the LockOutRealm to prevent attempts to guess user passwords
		           via a brute-force attack -->
		      <Realm className="org.apache.catalina.realm.LockOutRealm">
		        <!-- This Realm uses the UserDatabase configured in the global JNDI
		             resources under the key "UserDatabase".  Any edits
		             that are performed against this UserDatabase are immediately
		             available for use by the Realm.  -->
		        <Realm className="org.apache.catalina.realm.UserDatabaseRealm"
		               resourceName="UserDatabase"/>
		      </Realm>

		      <Host name="localhost"  appBase="webapps"
		            unpackWARs="true" autoDeploy="true">

		        <!-- SingleSignOn valve, share authentication between web applications
		             Documentation at: /docs/config/valve.html -->
		        <!--
		        <Valve className="org.apache.catalina.authenticator.SingleSignOn" />
		        -->

		        <!-- Access log processes all example.
		             Documentation at: /docs/config/valve.html
		             Note: The pattern used is equivalent to using pattern="common" -->
		        <Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs"
		               prefix="localhost_access_log." suffix=".txt"
		               pattern="%h %l %u %t &quot;%r&quot; %s %b" />

		      </Host>
		    </Engine>
		  </Service>
		</Server>






		'# 添加管理用户的配置信息'
		$ cat tomcat/templates/tomcat-users.xml.erb
		<?xml version='1.0' encoding='utf-8'?>
		<!--
		  Licensed to the Apache Software Foundation (ASF) under one or more
		  contributor license agreements.  See the NOTICE file distributed with
		  this work for additional information regarding copyright ownership.
		  The ASF licenses this file to You under the Apache License, Version 2.0
		  (the "License"); you may not use this file except in compliance with
		  the License.  You may obtain a copy of the License at

		      http://www.apache.org/licenses/LICENSE-2.0

		  Unless required by applicable law or agreed to in writing, software
		  distributed under the License is distributed on an "AS IS" BASIS,
		  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
		  See the License for the specific language governing permissions and
		  limitations under the License.
		-->
		<tomcat-users>
		<!--
		  NOTE:  By default, no user is included in the "manager-gui" role required
		  to operate the "/manager/html" web application.  If you wish to use this app,
		  you must define such a user - the username and password are arbitrary.
		-->
		<!--
		  NOTE:  The sample user and role entries below are wrapped in a comment
		  and thus are ignored when reading this file. Do not forget to remove
		  <!.. ..> that surrounds them.
		-->
		<!--
		  <role rolename="tomcat"/>
		  <role rolename="role1"/>
		  <user username="tomcat" password="tomcat" roles="tomcat"/>
		  <user username="both" password="tomcat" roles="tomcat,role1"/>
		  <user username="role1" password="tomcat" roles="role1"/>
		-->

		
		<role rolename="admin-gui"/>
		<role rolename="manager-gui"/>
		<user username="root" password="root@123" roles="manager-gui"/>
		<user username="tomcat" password="root@123" roles="admin-gui"/>
		<!-- <user name="admin" password="adminadmin" roles="admin,manager,admin-gui,admin-script,manager-gui,manager-script,manager-jmx,manager-status" /> -->
		</tomcat-users>





		'修改solo博客的配置：'
		$ vim tomcat/templates/local.properties.erb
		#
		# Copyright (c) 2010-2017, b3log.org & hacpai.com
		#
		# Licensed under the Apache License, Version 2.0 (the "License");
		# you may not use this file except in compliance with the License.
		# You may obtain a copy of the License at
		#
		#     http://www.apache.org/licenses/LICENSE-2.0
		#
		# Unless required by applicable law or agreed to in writing, software
		# distributed under the License is distributed on an "AS IS" BASIS,
		# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
		# See the License for the specific language governing permissions and
		# limitations under the License.
		#

		#
		# Description: Solo local environment configurations.
		# Version: 1.1.3.9, Sep 13, 2016
		# Author: Liang Ding
		#

		#### H2 runtime ####
		#runtimeDatabase=H2
		#jdbc.username=root
		#jdbc.password=
		#jdbc.driver=org.h2.Driver
		#jdbc.URL=jdbc:h2:~/solo_h2/db
		#jdbc.pool=h2

		#### MySQL runtime ####
		runtimeDatabase=MYSQL
		jdbc.username=solo
		jdbc.password=root@123
		jdbc.driver=com.mysql.jdbc.Driver
		jdbc.URL=jdbc:mysql://<%= @ipaddress %>:3306/solo?useUnicode=yes&characterEncoding=utf8
		jdbc.pool=druid

		# The minConnCnt MUST larger or equal to 3
		jdbc.minConnCnt=5
		jdbc.maxConnCnt=10

		# Be care to change the transaction isolation
		jdbc.transactionIsolation=REPEATABLE_READ

		# The specific table name prefix
		jdbc.tablePrefix=b3_solo



		'下载authbind绑定80端口的软件'
		$ wget https://s3.amazonaws.com/aaronsilber/public/authbind-2.1.1-0.1.x86_64.rpm
		$ cp authbind-2.1.1-0.1.x86_64.rpm /etc/puppet/modules/tomcat/files/


		'拷贝solo博客生成的程序文件至files：'
		$ mkdir /etc/puppet/modules/tomcat/files/ROOT
		$ cp -a /usr/share/tomcat/webapps/solo //etc/puppet/modules/tomcat/files/ROOT














	(5) solo博客配置文件：
		$ vim /usr/share/tomcat/webapps/solo/WEB-INF/classes/local.properties
		#
		# Copyright (c) 2010-2017, b3log.org & hacpai.com
		#
		# Licensed under the Apache License, Version 2.0 (the "License");
		# you may not use this file except in compliance with the License.
		# You may obtain a copy of the License at
		#
		#     http://www.apache.org/licenses/LICENSE-2.0
		#
		# Unless required by applicable law or agreed to in writing, software
		# distributed under the License is distributed on an "AS IS" BASIS,
		# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
		# See the License for the specific language governing permissions and
		# limitations under the License.
		#

		#
		# Description: Solo local environment configurations.
		# Version: 1.1.3.9, Sep 13, 2016
		# Author: Liang Ding
		#

		#### H2 runtime ####
		#runtimeDatabase=H2
		#jdbc.username=root
		#jdbc.password=
		#jdbc.driver=org.h2.Driver
		#jdbc.URL=jdbc:h2:~/solo_h2/db
		#jdbc.pool=h2

		#### MySQL runtime ####
		runtimeDatabase=MYSQL
		jdbc.username=solo
		jdbc.password=root@123
		jdbc.driver=com.mysql.jdbc.Driver
		jdbc.URL=jdbc:mysql://172.16.1.70:3306/solo?useUnicode=yes&characterEncoding=utf8
		jdbc.pool=druid

		# The minConnCnt MUST larger or equal to 3
		jdbc.minConnCnt=5
		jdbc.maxConnCnt=10

		# Be care to change the transaction isolation
		jdbc.transactionIsolation=REPEATABLE_READ

		# The specific table name prefix
		jdbc.tablePrefix=b3_solo




		'修改第二个配置文件'
 		$ cat solo/WEB-INF/classes/latke.properties
		#
		# Copyright (c) 2010-2017, b3log.org & hacpai.com
		#
		# Licensed under the Apache License, Version 2.0 (the "License");
		# you may not use this file except in compliance with the License.
		# You may obtain a copy of the License at
		#
		#     http://www.apache.org/licenses/LICENSE-2.0
		#
		# Unless required by applicable law or agreed to in writing, software
		# distributed under the License is distributed on an "AS IS" BASIS,
		# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
		# See the License for the specific language governing permissions and
		# limitations under the License.
		#

		#
		# Description: B3log Latke configurations. Configures the section "Server" carefully.
		# Version: 1.4.3.9, Dec 23, 2015
		# Author: Liang Ding
		#

		#### Server ####
		# Browser visit protocol
		serverScheme=http
		# Browser visit domain name
		serverHost=maxie.io
		# Browser visit port, 80 as usual, THIS IS NOT SERVER LISTEN PORT!
		serverPort=80

		#### Runtime Mode ####
		#runtimeMode=DEVELOPMENT
		runtimeMode=PRODUCTION










25、puppet的 master/agent配置：
	dev：开发节点  172.16.1.50   ->> puppet 、facter、 puppet-server 
	master:		  172.16.1.40  ->> puppet 、puppet-server 、facter
	node1:		  172.16.1.100 ->> puppet 、facter
	node2:		  172.16.1.70  ->> puppet 、facter


	安装之前配置主机名以及'同步时间'

		$ vim /etc/hosts 
		172.16.1.40 master.maxie.io master
		172.16.1.100 node1.maxie.io node1
		172.16.1.70 node2.maxie.io node2

		$ ntpdate 172.16.0.1

	

	(1) 安装master节点
		$ lftp 172.16.0.1/pub/Sources/7.x86_64/puppet
		> mget puppet-3.8.7-1.el7.noarch.rpm puppet-server-3.8.7-1.el7.noarch.rpm facter-2.4.6-1.el7.x86_64.rpm

		$ yum install ./*.rpm -y

		# 生成CA证书，并自建CA
		$ puppet master --no-daemonize -v
		Info: Creating a new SSL key for master.maxie.io
		Info: csr_attributes file loading from /etc/puppet/csr_attributes.yaml
		Info: Creating a new SSL certificate request for master.maxie.io
		Info: Certificate Request fingerprint (SHA256): 37:CB:C0:91:35:5D:F2:83:B7:16:36:73:30:80:74:2A:90:77:8A:C1:4F:10:4E:BE:14:E8:58:CC:83:CB:B7:76
		Notice: master.maxie.io has a waiting certificate request
		Notice: Signed certificate request for master.maxie.io
		Notice: Removing file Puppet::SSL::CertificateRequest master.maxie.io at '/var/lib/puppet/ssl/ca/requests/master.maxie.io.pem'
		Notice: Removing file Puppet::SSL::CertificateRequest master.maxie.io at '/var/lib/puppet/ssl/certificate_requests/master.maxie.io.pem'
		Notice: Starting Puppet master version 3.8.7

			'注意：这里如果报错是Could not create PID，需要执行以下命令'
				$ killall puppet 
				$ rm -rf /var/lib/puppet/ssl
				$ puppet master --no-daemonize -v


		# 查看端口是否启动,再打开一个终端
		$ ss -tnl | grep 8140


		# 将rpm包发送给agent
		$ scp -r ./*.rpm node2:/root
		$ scp -r ./*.rpm node1:/root



	(2) agent节点安装

		node1:
			$ rm -f puppet-server-3.8.7-1.el7.noarch.rpm
			$ yum install ./*.rpm -y
			$ rpm -ql puppet | less


			# 生成证书请求，等待CA master签署证书
			$ puppet agent --server master.maxie.io --no-daemonize -v
			Info: Caching certificate for ca
			Info: csr_attributes file loading from /etc/puppet/csr_attributes.yaml
			Info: Creating a new SSL certificate request for node1.maxie.io
			Info: Certificate Request fingerprint (SHA256): F4:63:3E:68:8A:E2:C2:B4:83:81:C6:E1:7C:28:40:92:6A:56:26:3D:CC:39:8A:30:E7:D1:39:E4:11:F3:CB:68
	

	(3) master节点签署node1节点、node2节点的证书请求
		# 列出需要签署的证书
		$ puppet cert list 

		# 签署指定主机的证书
		$ puppet cert sign node1.maxie.io 

		# 签署所有请求的证书
		$ puppet cert sign --all 


	(4) node1 agent节点查看收到CA签署完成后的证书
		
		$ puppet agent --server master.maxie.io --no-daemonize -v
		Info: Caching certificate for ca
		Info: csr_attributes file loading from /etc/puppet/csr_attributes.yaml
		Info: Creating a new SSL certificate request for node1.maxie.io
		Info: Certificate Request fingerprint (SHA256): F4:63:3E:68:8A:E2:C2:B4:83:81:C6:E1:7C:28:40:92:6A:56:26:3D:CC:39:8A:30:E7:D1:39:E4:11:F3:CB:68
		Info: Caching certificate for ca
		Info: Caching certificate for node1.maxie.io
		Notice: Starting Puppet client version 3.8.7
		Info: Caching certificate_revocation_list for ca
		Warning: Unable to fetch my node definition, but the agent run will continue:
		Warning: undefined method 'include?' for nil:NilClass
		Info: Retrieving pluginfacts
		Info: Retrieving plugin
		Info: Caching catalog for node1.maxie.io
		Info: Applying configuration version '1500621510'
		Info: Creating state file /var/lib/puppet/state/state.yaml
		Notice: Finished catalog run in 0.01 seconds

		
		但是现在我们还没有给agent定义其使用的模块，所以下面我们开始定义


	(5) 配置master上的模块文件：
		$ mkdir -pv /etc/puppet/modules/chrony/{manifests,files,templates,lib,spec,tests}
		$ cd /etc/puppet/modules/chrony/manifests/
		$ vim init.pp
		# Class: chrony
		#
		# This module manages CHRONY
		#
		#

		class chrony {
		        package{'chrony':
		                ensure  => latest,
		        } ->

		        file{'chrony.conf':
		                ensure  => file,
		                path    => '/etc/chrony.conf',
		                source  => 'puppet:///modules/chrony/chrony.conf',
		        } ~>

		        service{'chronyd':
		                ensure  => running,
		                enable  => true,
		        }
		}

		$ vim ../files/chrony.conf 
		# Use public servers from the pool.ntp.org project.
		# Please consider joining the pool (http://www.pool.ntp.org/join.html).
		server 172.16.0.1 iburst
		# Ignore stratum in source selection.
		stratumweight 0

		# Record the rate at which the system clock gains/losses time.
		driftfile /var/lib/chrony/drift

		# Enable kernel RTC synchronization.
		rtcsync

		# In first three updates step the system clock instead of slew
		# if the adjustment is larger than 10 seconds.
		makestep 10 3

		# Allow NTP client access from local network.
		#allow 192.168/16

		# Listen for commands only on localhost.
		bindcmdaddress 127.0.0.1
		bindcmdaddress ::1

		# Serve time even if not synchronized to any NTP server.
		#local stratum 10

		keyfile /etc/chrony.keys

		# Specify the key used as password for chronyc.
		commandkey 1

		# Generate command key if missing.
		generatecommandkey

		# Disable logging of client accesses.
		noclientlog

		# Send a message to syslog if a clock adjustment is larger than 0.5 seconds.
		logchange 0.5

		logdir /var/log/chrony
		#log measurements statistics tracking


	(6) 编辑master上 站点清单 site.pp文件 

		$ cd /etc/puppet/manifests/
		$ vim site.pp
		node 'node1.maxie.io' {
		        include chrony
		}


	(7) node1节点上重新启动agent服务，获取master节点为我们配置的站点清单

		$ puppet agent --server master.maxie.io --no-daemonize -v
		Notice: Starting Puppet client version 3.8.7
		Info: Retrieving pluginfacts
		Info: Retrieving plugin
		Info: Caching catalog for node1.maxie.io
		Info: Applying configuration version '1500622364'
		Info: Computing checksum on file /etc/chrony.conf
		Info: /Stage[main]/Chrony/File[chrony.conf]: Filebucketed /etc/chrony.conf to puppet with sum f9b03c5e44a754c3ffd8e135a0a3b35e
		Notice: /Stage[main]/Chrony/File[chrony.conf]/content: content changed '{md5}f9b03c5e44a754c3ffd8e135a0a3b35e' to '{md5}37d1ea0abc9e2a92adb512e392fdb033'
		Info: /Stage[main]/Chrony/File[chrony.conf]: Scheduling refresh of Service[chronyd]
		Notice: /Stage[main]/Chrony/Service[chronyd]: Triggered 'refresh' from 1 events
		Notice: Finished catalog run in 0.74 seconds


		这次，不在报错，Warning: Unable to fetch my node definition, but the agent run will continue:
					  Warning: undefined method 'include?' for nil:NilClass
			这个错，主要是没有抓取到master节点为我们配置的站点清单，所以报错

		
		如果想看详细信息的输出结果，使用： 加上-d 也就是debug
			$ puppet agent --server master.maxie.io --no-daemonize -v -d 

	

	(8) 上面这些我们都使用的 no-daemonize 模式，现在只需修改配置文件，然后使用systemctl启动agent服务即可
		node1： 
			$ vim /etc/puppet/puppet.conf 
			在[agent]最后一行添加：
				server = master.maxie.io

			$ systemctl start puppetagent.service 
			# 当前没有监听端口，只有之后配置kick时，需要监听
			$ ss -tnl 

		master： 
			$ systemctl start puppetnaster.service 
			$ ss -tnl | 8140 


	(9) 配置'agent kick功能'：
		node1 AND node2 ：
			
			'# 行尾设置为如下信息'
			$ vim /etc/puppet/auth.conf 
			# deny everything else; this ACL is not strictly necessary, but
			# illustrates the default policy.
			path /
			auth any
			allow master.maxie.io

			#
			path /run
			method save
			auth any
			allow master.maxie.io

			'在main段添加以下信息'：
			$ vim /etc/puppet/puppet.conf 
			[main]
			    listen = true 

			'重启服务'
			$ systemctl restart puppetagent.service 

			'查看端口是否监听'
			$ ss -tnl | grep 8139



		'master节点'
			$ puppet kick node1.maxie.io 
			$ puppet kick node2.maxie.io 

			或者

			$ puppet kick --all






26、使用master/agent模式配置 LNAMT --> 

	在25的基础上，只需将我们之前的单个配置中关于一些节点的IP地址修改为 需要的 主机名即可


	'master节点：'
		(1) 修改Nginx模块的模板文件
		$ vim /etc/puppet/modules/nginx/templates/nginx.conf.erb
		# For more information on configuration, see:
		#   * Official English Documentation: http://nginx.org/en/docs/
		#   * Official Russian Documentation: http://nginx.org/ru/docs/

		user nginx;
		worker_processes <%= @processorcount %>;
		error_log /var/log/nginx/error.log;
		pid /run/nginx.pid;

		# Load dynamic modules. See /usr/share/nginx/README.dynamic.
		include /usr/share/nginx/modules/*.conf;

		events {
		    worker_connections 1024;
		}

		http {
		    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
		                      '$status $body_bytes_sent "$http_referer" '
		                      '"$http_user_agent" "$http_x_forwarded_for"';

		    access_log  /var/log/nginx/access.log  main;

		    sendfile            on;
		    tcp_nopush          on;
		    tcp_nodelay         on;
		    keepalive_timeout   65;
		    types_hash_max_size 2048;

		    include             /etc/nginx/mime.types;
		    default_type        application/octet-stream;

		    # Load modular configuration files from the /etc/nginx/conf.d directory.
		    # See http://nginx.org/en/docs/ngx_core_module.html#include
		    # for more information.
		    include /etc/nginx/conf.d/*.conf;

		    server {
		        listen       80 default_server;
		        listen       [::]:80 default_server;
		        root         /usr/share/nginx/html;

		        include /etc/nginx/default.d/*.conf;

			server_name	<%= @domain %>;
			index 	index.html;

		        location / {
		       		proxy_set_header    X-Forwarded-For $remote_addr;
		        	proxy_buffering        off;
		        	proxy_pass        http://node2.maxie.io:808;
		        }


		        error_page 404 /404.html;
		            location = /40x.html {
		        }

		        error_page 500 502 503 504 /50x.html;
		            location = /50x.html {
		        }
		    }
		}



		(2) 











27、配置memcached模块：
	
	(1) 配置tomcat支持memcached：


		'两台tomcat都要操作'
		$ vim /etc/tomcat/server.xml
		<?xml version='1.0' encoding='utf-8'?>
		<!--
		  Licensed to the Apache Software Foundation (ASF) under one or more
		  contributor license agreements.  See the NOTICE file distributed with
		  this work for additional information regarding copyright ownership.
		  The ASF licenses this file to You under the Apache License, Version 2.0
		  (the "License"); you may not use this file except in compliance with
		  the License.  You may obtain a copy of the License at

		      http://www.apache.org/licenses/LICENSE-2.0

		  Unless required by applicable law or agreed to in writing, software
		  distributed under the License is distributed on an "AS IS" BASIS,
		  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
		  See the License for the specific language governing permissions and
		  limitations under the License.
		-->
		<!-- Note:  A "Server" is not itself a "Container", so you may not
		     define subcomponents such as "Valves" at this level.
		     Documentation at /docs/config/server.html
		 -->
		<Server port="8005" shutdown="SHUTDOWN">
		  <!-- Security listener. Documentation at /docs/config/listeners.html
		  <Listener className="org.apache.catalina.security.SecurityListener" />
		  -->
		  <!--APR library loader. Documentation at /docs/apr.html -->
		  <Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" />
		  <!--Initialize Jasper prior to webapps are loaded. Documentation at /docs/jasper-howto.html -->
		  <Listener className="org.apache.catalina.core.JasperListener" />
		  <!-- Prevent memory leaks due to use of particular java/javax APIs-->
		  <Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" />
		  <Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" />
		  <Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" />

		  <!-- Global JNDI resources
		       Documentation at /docs/jndi-resources-howto.html
		  -->
		  <GlobalNamingResources>
		    <!-- Editable user database that can also be used by
		         UserDatabaseRealm to authenticate users
		    -->
		    <Resource name="UserDatabase" auth="Container"
		              type="org.apache.catalina.UserDatabase"
		              description="User database that can be updated and saved"
		              factory="org.apache.catalina.users.MemoryUserDatabaseFactory"
		              pathname="conf/tomcat-users.xml" />
		  </GlobalNamingResources>

		  <!-- A "Service" is a collection of one or more "Connectors" that share
		       a single "Container" Note:  A "Service" is not itself a "Container",
		       so you may not define subcomponents such as "Valves" at this level.
		       Documentation at /docs/config/service.html
		   -->
		  <Service name="Catalina">

		    <!--The connectors can use a shared executor, you can define one or more named thread pools-->
		    <!--
		    <Executor name="tomcatThreadPool" namePrefix="catalina-exec-"
		        maxThreads="150" minSpareThreads="4"/>
		    -->


		    <!-- A "Connector" represents an endpoint by which requests are received
		         and responses are returned. Documentation at :
		         Java HTTP Connector: /docs/config/http.html (blocking & non-blocking)
		         Java AJP  Connector: /docs/config/ajp.html
		         APR (HTTP/AJP) Connector: /docs/apr.html
		         Define a non-SSL HTTP/1.1 Connector on port 8080
		    -->
		    <Connector port="8080" protocol="HTTP/1.1"
		               connectionTimeout="20000"
			       URIEncoding="UTF-8"
			       Server="mAX io site"
		               redirectPort="8443" />
		    <!-- A "Connector" using the shared thread pool-->
		    <!--
		    <Connector executor="tomcatThreadPool"
		               port="8080" protocol="HTTP/1.1"
		               connectionTimeout="20000"
		               redirectPort="8443" />
		    -->
		    <!-- Define a SSL HTTP/1.1 Connector on port 8443
		         This connector uses the BIO implementation that requires the JSSE
		         style configuration. When using the APR/native implementation, the
		         OpenSSL style configuration is required as described in the APR/native
		         documentation -->
		    <!--
		    <Connector port="8443" protocol="org.apache.coyote.http11.Http11Protocol"
		               maxThreads="150" SSLEnabled="true" scheme="https" secure="true"
		               clientAuth="false" sslProtocol="TLS" />
		    -->

		    <!-- Define an AJP 1.3 Connector on port 8009 -->
		    <Connector port="8009" protocol="AJP/1.3" redirectPort="8443" />


		    <!-- An Engine represents the entry point (within Catalina) that processes
		         every request.  The Engine implementation for Tomcat stand alone
		         analyzes the HTTP headers included with the request, and passes them
		         on to the appropriate Host (virtual host).
		         Documentation at /docs/config/engine.html -->

		    <!-- You should set jvmRoute to support load-balancing via AJP ie :
		    <Engine name="Catalina" defaultHost="localhost" jvmRoute="jvm1">
		    -->
		    <Engine name="Catalina" defaultHost="localhost">

		      <!--For clustering, please take a look at documentation at:
		          /docs/cluster-howto.html  (simple how to)
		          /docs/config/cluster.html (reference documentation) -->
		      <!--
		      <Cluster className="org.apache.catalina.ha.tcp.SimpleTcpCluster"/>
		      -->

		      <!-- Use the LockOutRealm to prevent attempts to guess user passwords
		           via a brute-force attack -->
		      <Realm className="org.apache.catalina.realm.LockOutRealm">
		        <!-- This Realm uses the UserDatabase configured in the global JNDI
		             resources under the key "UserDatabase".  Any edits
		             that are performed against this UserDatabase are immediately
		             available for use by the Realm.  -->
		        <Realm className="org.apache.catalina.realm.UserDatabaseRealm"
		               resourceName="UserDatabase"/>
		      </Realm>

		      <Host name="localhost"  appBase="webapps"
		            unpackWARs="true" autoDeploy="true">


		<Context path="/test" docBase="test" reloadable="true" >
		            <Manager className="de.javakaffee.web.msm.MemcachedBackupSessionManager"
		                memcachedNodes="mem1:172.16.1.110:11211,mem2:172.16.1.50:11211"
		                failoverNodes="mem2"
		                requestUriIgnorePattern=".*\.(ico|png|gif|jpg|css|js)$"
		                transcoderFactoryClass="de.javakaffee.web.msm.serializer.javolution.JavolutionTranscoderFactory"
		            />
		        </Context>

		        <!-- SingleSignOn valve, share authentication between web applications
		             Documentation at: /docs/config/valve.html -->
		        <!--
		        <Valve className="org.apache.catalina.authenticator.SingleSignOn" />
		        -->

		        <!-- Access log processes all example.
		             Documentation at: /docs/config/valve.html
		             Note: The pattern used is equivalent to using pattern="common" -->
		        <Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs"
		               prefix="localhost_access_log." suffix=".txt"
		               pattern="%h %l %u %t &quot;%r&quot; %s %b" />

		      </Host>
		    </Engine>
		  </Service>
		</Server>







		'创建会话保持测试页：'  --> 注意两台tomcat的测试页，需要有些不同，用以区别

			$ mkdir -pv /usr/share/tomcat/webapps/test/{WEB-INF,classes,META-INF}
			
			'tomcat1：'
			$ vim /usr/share/tomcat/webapps/test/index.jsp
			<%@ page language="java" %>
			<%@ page import="java.util.*" %>
			<html>
				<head>
			   	 <title>Server One</title>
				</head>
				<body>
			    		<font size=10 color="#38B0DE" > Tomcat First Server  </font>
			    		<table align="centre" border="1">
			    		<tr>
			          		  <td>Session ID</td>
			           		  <% session.setAttribute("maxie.io","maxie.io"); %>
			            		  <td><%= session.getId() %></td>
			  		</tr>
			    		<tr>
			           		 <td>Created on</td>
			                    		<td><%= session.getCreationTime() %></td>
			            	</tr>
			    		</table>
			   		<br>
			    		<% out.println("China NO.1");
			   		 %>
				</body>
			</html>


			'tomcat2：'
			<%@ page language="java" %>
			<%@ page import="java.util.*" %>
			<html>
				<head>
			   	 <title>Server Two</title>
				</head>
				<body>
			    		<font size=10 color="#32CD99" > Tomcat Second Server  </font>
			    		<table align="centre" border="1">
			    		<tr>
			          		  <td>Session ID</td>
			           		  <% session.setAttribute("maxie.io","maxie.io"); %>
			            		  <td><%= session.getId() %></td>
			  		</tr>
			    		<tr>
			           		 <td>Created on</td>
			                    		<td><%= session.getCreationTime() %></td>
			            	</tr>
			    		</table>
			   		<br>
			    		<% out.println("Taiwan No.1");
			   		 %>
				</body>
			</html>




		'拷贝msm jar包至/usr/share/java/tomcat/'	--> 下载包应该放在网盘，用以提供
		$ cd /usr/share/java/tomcat/
		$ wget ftp://172.16.0.1/pub/Sources/7.x86_64/msm/*
		$ rm -f memcached-session-manager-tc8-1.8.3.jar



		'等待memcached服务器配置完成，重启tomcat即可'



	(2) 配置memcached服务器(两台)：
		$ yum install -y memcached 
		# memcached配置文件，一般无需修改
		$ vim /etc/sysconfig/memcached

		$ systemctl start memcached 

		$ ss -tnl | grep 11211


	(3) 在tomcat的两台服务器上配置httpd反代tomcat，再另建一台nginx，用作负载均衡调度后端 httpd
		'tomcat '： 
			$ yum install -y httpd
			$ vim /etc/httpd/conf.d/maxie.conf 
			<VirtualHost 172.16.1.60:80>
		        ServerName maxie.io:80
		        ProxyRequests Off
		        ProxyVia On
		        ProxyPreserveHost On
		        <Proxy *>
		                Require all granted
		        </Proxy>
		        ProxyPass       /       http://172.16.1.60:8080/

		        <Location />
		                Require all granted
		        </Location>
		       CustomLog "/var/log/httpd//maxie_access.log" combined
			</VirtualHost>

			$ systemctl start httpd 



		'nginx反代：'
			$ yum install -y nginx 
			$ vim /etc/nginx/conf.d/maxie.conf 
			upstream tomcatsrvs {
			        server 172.16.1.60:80;
			        server 172.16.1.80:80;
			}

			server {
			        listen  80;
			        server_name     maxie.io;
			        location / {
			                proxy_pass      http://tomcatsrvs;
			        }
			}

			$ nginx -t 
			$ systemctl start nginx 


		'打开浏览器验证：'
			https://ws4.sinaimg.cn/large/006tNc79ly1fhsfdzfswjg30qo0fgnpg.gif







	(4) '制作memcached模块：' --> master节点
		$ mkdir -pv /etc/puppet/modules/memcached/{manifests,files,templates,lib,tests,spec}
		$ cd /etc/puppet/modules/memcached
		$ vim manifests/init.pp
		class memcached {
		        package{'memcached':
		                ensure  => latest,
		        } ->

		        service{'memcached':
		                ensure  => running,
		                enable  => true,
		        }
		}



	(5) '制作tomcat连接memcached的资源清单'： 
		备份我们之前做的tomcat的模块

		$ cp -a /etc/puppet/modules/tomcat /root/backup/


	!!!	开始制作
			$ cd /etc/puppet/modules/tomcat/
			$ vim manifests/mem.pp
			class tomcat::mem inherits tomcat {
			exec{'mkdir':
				command	=> 'mkdir -p /usr/share/tomcat/webapps/test/{WEB-INF,classes,META-INF}',
				path    => '/bin:/sbin:/usr/bin:/usr/sbin',
			}

			file{'index.jsp':
				ensure	=> file,
				path	=> '/usr/share/tomcat/webapps/test/index.jsp',
				source	=> 'puppet:///modules/tomcat/index.jsp',
				require	=> Exec['mkdir'],
			}

			file{'javolution-5.4.3.1.jar':
				ensure	=> file,
				path	=> '/usr/share/java/tomcat/javolution-5.4.3.1.jar',
				source	=> 'puppet:///modules/tomcat/javolution-5.4.3.1.jar',
				require	=> Exec['mkdir'],
			}

			file{'memcached-session-manager-1.8.3.jar':
				ensure	=> file,
				path	=> '/usr/share/java/tomcat/memcached-session-manager-1.8.3.jar',
				source	=> 'puppet:///modules/tomcat/memcached-session-manager-1.8.3.jar',
				require	=> Exec['mkdir'],
			}

			file{'memcached-session-manager-tc7-1.8.3.jar':
				ensure	=> file,
				path	=> '/usr/share/java/tomcat/memcached-session-manager-tc7-1.8.3.jar',
				source	=> 'puppet:///modules/tomcat/memcached-session-manager-tc7-1.8.3.jar',
				require	=> Exec['mkdir'],
			}

			file{'msm-javolution-serializer-1.8.3.jar':
				ensure	=> file,
				path	=> '/usr/share/java/tomcat/msm-javolution-serializer-1.8.3.jar',
				source	=> 'puppet:///modules/tomcat/msm-javolution-serializer-1.8.3.jar',
				require	=> Exec['mkdir'],
			}

			file{'spymemcached-2.11.1.jar':
				ensure	=> file,
				path	=> '/usr/share/java/tomcat/spymemcached-2.11.1.jar',
				source	=> 'puppet:///modules/tomcat/spymemcached-2.11.1.jar',
				require	=> Exec['mkdir'],
			}

			Package['java-1.8.0-openjdk-devel','tomcat','tomcat-admin-webapps','tomcat-webapps'] -> Exec['mkdir']
		}






		'修改之前的tomcat::blog中local.properties资源的定义'
			$ vim manifests/blog.pp
			class tomcat::blog inherits tomcat {

				file{'ROOT':
			                ensure  => directory,
			                path    => '/usr/share/tomcat/webapps/ROOT/',
			                source  => 'puppet:///modules/tomcat/ROOT/',
			                replace => true,
			                recurse => true,
			                owner   => 'tomcat',
			                group   => 'tomcat',
			        }

				file{'local.properties':
					ensure	=> file,
					path	=> '/usr/share/tomcat/webapps/ROOT/WEB-INF/classes/local.properties',
					replace	=> true,
					owner	=> 'tomcat',
					group	=> 'tomcat',
					# 这里使用定义好的，而非模板，主要是我们要使用同一个数据库
					source	=> 'puppet:///tomcat/local.properties',
					require	=> File['ROOT'],
				}

				Package['tomcat'] -> File['ROOT']

			}

			$ mv /etc/puppet/modules/tomcat/templates/local.properties.erb /etc/puppet/modules/tomcat/files/local.properties

			$ vim /etc/puppet/modules/tomcat/files/local.properties
			#### MySQL runtime ####
			runtimeDatabase=MYSQL
			jdbc.username=solo
			jdbc.password=root@123
			jdbc.driver=com.mysql.jdbc.Driver
			# 填写固定数据库地址
			jdbc.URL=jdbc:mysql://172.16.1.70:3306/solo?useUnicode=yes&characterEncoding=utf8
			jdbc.pool=druid






		'创建所需的文件和jar包'


			'tomcat1'
			$ vim files/tom1-index.jsp
			<%@ page language="java" %>
			<%@ page import="java.util.*" %>
			<html>
			    <head>
			        <title>Server One</title>
			    </head>
			    <body>
			            <font size=10 color="#38B0DE" > Tomcat Server  One</font>
			            <table align="centre" border="1">
			            <tr>
			                    <td>Session ID</td>
			                     <% session.setAttribute("maxie.io","maxie.io"); %>
			                      <td><%= session.getId() %></td>
			          </tr>
			            <tr>
			                    <td>Created on</td>
			                            <td><%= session.getCreationTime() %></td>
			                </tr>
			            </table>
			           <br>
			           <% out.println("China No.1");
			   		 %>
			    </body>
			</html>



			'tomcat2'
			$ vim files/tom2-index.jsp
			<%@ page language="java" %>
			<%@ page import="java.util.*" %>
			<html>
			    <head>
			        <title>Server Second</title>
			    </head>
			    <body>
			            <font size=10 color="#32CD99" > Tomcat Server  </font>
			            <table align="centre" border="1">
			            <tr>
			                    <td>Session ID</td>
			                     <% session.setAttribute("maxie.io","maxie.io"); %>
			                      <td><%= session.getId() %></td>
			          </tr>
			            <tr>
			                    <td>Created on</td>
			                            <td><%= session.getCreationTime() %></td>
			                </tr>
			            </table>
			           <br>
			           <% out.println("Taiwan No.2");
			   		 %>
			    </body>
			</html>


			$ cd files 
			$ wget ftp://172.16.0.1/pub/Sources/7.x86_64/msm/*
			$ rm -f memcached-session-manager-tc8-1.8.3.jar






	(6)	'编辑master的site.pp文件'
			$ vim /etc/puppet/manifests/site.pp
			manifests/site.pp
			node 'base' {
				include	chrony
			}
			node 'node1.maxie.io' {
				include	nginx
				include	nginx::tomcatsrvs
			}

			node 'node2.maxie.io' {
				include	mariadb
				# 此指令只能执行一次，第二次需要将其删除
				include mariadb::database
				include	httpd
				include	httpd::httpdconf
				include	httpd::vhost
				include	tomcat
				include	tomcat::memconf
				include	tomcat::blog
				include tomcat::memone
				include	memcached
				include	tomcat::authbind
			}

			node 'node3.maxie.io' {
				include	mariadb
				# 此指令只能执行一次，第二次需要将其删除
				include	mariadb::database
				include	httpd
				include	httpd::httpdconf
				include	httpd::vhost
				include	tomcat
				include	tomcat::memconf
				include	tomcat::blog
				include tomcat::memtwo
				include	memcached
				include	tomcat::authbind
			}


	(7) '编辑node3节点配置：使其成为agent节点'

		node3： 172.16.1.60

		$ vim /etc/hosts
		172.16.1.40 master.maxie.io master 
		172.16.1.100 node1.maxie.io node1 
		172.16.1.70 node2.maxie.io node2
		172.16.1.60 node3.maxie.io node3

		$ scp /etc/hosts master:/etc/
		$ scp /etc/hosts node1:/etc/
		$ scp /etc/hosts node2:/etc/

		$ wget ftp://172.16.0.1/pub/Sources/7.x86_64/puppet/facter-2.4.6-1.el7.x86_64.rpm
		$ wget ftp://172.16.0.1/pub/Sources/7.x86_64/puppet/puppet-3.8.7-1.el7.noarch.rpm

		$ yum install -y ./*.rpm 

		$ vim /etc/puppet/puppet.conf 
		[main]
		listen = true 

		[agent]
		server = master.maxie.io


		# 测试是否正常，如需详细信息再加上 -d选项 也就是debug 
		# 不过第一次需要让master给我们签署CA证书，此步骤需要执行两次。
		$ puppet agent --server master.maxie.io --no-daemonize -v --noop

		master节点签署请求：
		$ puppet cert sign node3.maxie.io 

		# 再次请求
		$ puppet agent --server master.maxie.io --no-daemonize -v --noop

		# 测试成功后，取消--noop选项
		# 如果没有报错，并且提示信息为：Finished catalog run in 8.37 seconds
		# 则获取配置信息正常，只需检测服务是否启动
		$ ss -tnl 




	(8) 由于我们这样做了2个tomcat节点，之前的nginx就需要修改了或者添加一个新的资源清单即可
		'修改nginx模块： '

		$ vim /etc/puppet/modules/nginx/manifests/tomcatsrvs.pp
		class nginx::tomcatsrvs inherits nginx {
		        file{'nginx-tomcat.conf':
		                ensure  => file,
		                path    => '/etc/nginx/nginx.conf',
		                content => template('nginx/nginx-tomcat.conf.erb'),
		        }

		        Package['nginx'] -> File['nginx-tomcat.conf']  ~> Service['nginx']
		}

		$ cp modules/nginx/templates/nginx.conf.erb modules/nginx/templates/nginx-tomcat.conf.erb
		$ vim modules/nginx/templates/nginx-tomcat.conf.erb
		# For more information on configuration, see:
		#   * Official English Documentation: http://nginx.org/en/docs/
		#   * Official Russian Documentation: http://nginx.org/ru/docs/

		user nginx;
		worker_processes <%= @processorcount %>;
		error_log /var/log/nginx/error.log;
		pid /run/nginx.pid;

		# Load dynamic modules. See /usr/share/nginx/README.dynamic.
		include /usr/share/nginx/modules/*.conf;

		events {
		    worker_connections 1024;
		}

		http {
		    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
		                      '$status $body_bytes_sent "$http_referer" '
		                      '"$http_user_agent" "$http_x_forwarded_for"';

		    access_log  /var/log/nginx/access.log  main;

		    sendfile            on;
		    tcp_nopush          on;
		    tcp_nodelay         on;
		    keepalive_timeout   65;
		    types_hash_max_size 2048;

		    include             /etc/nginx/mime.types;
		    default_type        application/octet-stream;

		    include /etc/nginx/conf.d/*.conf;

		    upstream tomcatsrvs {
			server node2.maxie.io:80;
		        server node3.maxie.io:80;
		    }

		    server {
		        listen       80 default_server;
		        listen       [::]:80 default_server;
		        root         /usr/share/nginx/html;

		        include /etc/nginx/default.d/*.conf;

			server_name	<%= @domain %>;
			index 	index.html;

		        location / {
		       		proxy_set_header    X-Forwarded-For $remote_addr;
		        	proxy_buffering        off;
		        	proxy_pass        http://tomcatsrvs;
		        }


		        error_page 404 /404.html;
		            location = /40x.html {
		        }

		        error_page 500 502 503 504 /50x.html;
		            location = /50x.html {
		        }
		    }
		}


		修改master节点对node1的分发配置：site.pp
		$ vim /etc/puppet/manifests/site.pp
			manifests/site.pp
			node 'base' {
				include	chrony
			}
			node 'node1.maxie.io' {
				include	nginx
				include	nginx::tomcatsrvs
			}


		修改之后，在node1节点，也就是我们nginx反代的节点，重新获取配置信息

		$ puppet agent --server master.maxie.io --no-daemonize -v

		然后查看node1节点的nginx配置文件是否修改成功

	


	(9) 修改本机hosts文件：
		$ vim /etc/hosts 
		172.16.1.100 maxie.io


		浏览器访问：
			https://ws2.sinaimg.cn/large/006tNc79ly1fhsk0cisdgg30qo0fg7wo.gif





		












































